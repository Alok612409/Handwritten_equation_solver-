{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hanwritten Equation Solver.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization of CNN Model"
      ],
      "metadata": {
        "id": "yFjgOHptiVDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do upload the model folder from github before running this cell"
      ],
      "metadata": {
        "id": "APmNmdGnjM9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.models import Sequential, model_from_json\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from os.path import isfile, join\n",
        "from keras import backend as K\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "\n",
        "index_by_directory = {\n",
        "    '0': 0,\n",
        "    '1': 1,\n",
        "    '2': 2,\n",
        "    '3': 3,\n",
        "    '4': 4,\n",
        "    '5': 5,\n",
        "    '6': 6,\n",
        "    '7': 7,\n",
        "    '8': 8,\n",
        "    '9': 9,\n",
        "    '+': 10,\n",
        "    '-': 11,\n",
        "    'x': 12,\n",
        "    'a':13,\n",
        "    'b':14\n",
        "}\n",
        "   \n",
        "\n",
        "def get_index_by_directory(directory):\n",
        "    return index_by_directory[directory]\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    train_data = []\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename), cv2.IMREAD_GRAYSCALE) # Convert to Image to Grayscale\n",
        "        img = ~img # Invert the bits of image 255 -> 0\n",
        "        if img is not None:\n",
        "            _, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) # Set bits > 127 to 1 and <= 127 to 0\n",
        "            ctrs, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "            cnt = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0]) # Sort by x\n",
        "            maxi = 0\n",
        "            for c in cnt:\n",
        "                x, y, w, h = cv2.boundingRect(c)\n",
        "                maxi = max(w*h, maxi)\n",
        "                if maxi == w*h:\n",
        "                    x_max = x\n",
        "                    y_max = y\n",
        "                    w_max = w\n",
        "                    h_max = h\n",
        "            im_crop = thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10] # Crop the image as most as possible\n",
        "            im_resize = cv2.resize(im_crop, (28, 28)) # Resize to (28, 28)\n",
        "            im_resize = np.reshape(im_resize, (784, 1)) # Flat the matrix\n",
        "            train_data.append(im_resize)\n",
        "    return train_data\n",
        "\n",
        "def load_all_imgs():\n",
        "    dataset_dir = \"./datasets/\"\n",
        "    directory_list = listdir(dataset_dir)\n",
        "    first = True\n",
        "    data = []\n",
        "\n",
        "    print('Exporting images...')\n",
        "    for directory in directory_list:\n",
        "        print(directory)\n",
        "        if first:\n",
        "            first = False\n",
        "            data = load_images_from_folder(dataset_dir + directory)\n",
        "            for i in range(0, len(data)):\n",
        "                data[i] = np.append(data[i], [str(get_index_by_directory(directory))])\n",
        "            continue\n",
        "\n",
        "        aux_data = load_images_from_folder(dataset_dir + directory)\n",
        "        for i in range(0, len(aux_data)):\n",
        "            aux_data[i] = np.append(aux_data[i], [str(get_index_by_directory(directory))])\n",
        "        data = np.concatenate((data, aux_data))\n",
        "\n",
        "    df=pd.DataFrame(data,index=None)\n",
        "    df.to_csv('model/train_data.csv',index=False)\n",
        "\n",
        "def extract_imgs(img):\n",
        "    img = ~img # Invert the bits of image 255 -> 0\n",
        "    _, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) # Set bits > 127 to 1 and <= 127 to 0\n",
        "    ctrs, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0]) # Sort by x\n",
        "\n",
        "    img_data = []\n",
        "    rects = []\n",
        "    for c in cnt :\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        rect = [x, y, w, h]\n",
        "        rects.append(rect)\n",
        "\n",
        "    bool_rect = []\n",
        "    # Check when two rectangles collide\n",
        "    for r in rects:\n",
        "        l = []\n",
        "        for rec in rects:\n",
        "            flag = 0\n",
        "            if rec != r:\n",
        "                if r[0] < (rec[0] + rec[2] + 10) and rec[0] < (r[0] + r[2] + 10) and r[1] < (rec[1] + rec[3] + 10) and rec[1] < (r[1] + r[3] + 10):\n",
        "                    flag = 1\n",
        "                l.append(flag)\n",
        "            else:\n",
        "                l.append(0)\n",
        "        bool_rect.append(l)\n",
        "\n",
        "    dump_rect = []\n",
        "    # Discard the small collide rectangle\n",
        "    for i in range(0, len(cnt)):\n",
        "        for j in range(0, len(cnt)):\n",
        "            if bool_rect[i][j] == 1:\n",
        "                area1 = rects[i][2] * rects[i][3]\n",
        "                area2 = rects[j][2] * rects[j][3]\n",
        "                if(area1 == min(area1,area2)):\n",
        "                    dump_rect.append(rects[i])\n",
        "\n",
        "    # Get the final rectangles\n",
        "    final_rect = [i for i in rects if i not in dump_rect]\n",
        "    for r in final_rect:\n",
        "        x = r[0]\n",
        "        y = r[1]\n",
        "        w = r[2]\n",
        "        h = r[3]\n",
        "\n",
        "        im_crop = thresh[y:y+h+10, x:x+w+10] # Crop the image as most as possible\n",
        "        im_resize = cv2.resize(im_crop, (28, 28)) # Resize to (28, 28)\n",
        "        im_resize = np.reshape(im_resize, (1, 28, 28)) # Flat the matrix\n",
        "        img_data.append(im_resize)\n",
        "\n",
        "    return img_data\n",
        "\n",
        "class ConvolutionalNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        if os.path.exists('model/model_weights.h5') and os.path.exists('model/model.json'):\n",
        "            self.load_model()\n",
        "        else:\n",
        "            self.create_model()\n",
        "            self.train_model()\n",
        "            self.export_model()\n",
        "\n",
        "    def create_model(self):\n",
        "        first_conv_num_filters = 30\n",
        "        first_conv_filter_size = 5\n",
        "        second_conv_num_filters = 15\n",
        "        second_conv_filter_size = 3\n",
        "        pool_size = 2\n",
        "\n",
        "        # Create model\n",
        "        print(\"Creating Model...\")\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Conv2D(first_conv_num_filters, first_conv_filter_size, input_shape=(28, 28, 1), activation='relu'))\n",
        "        self.model.add(MaxPooling2D(pool_size=pool_size))\n",
        "        self.model.add(Conv2D(second_conv_num_filters, second_conv_filter_size, activation='relu'))\n",
        "        self.model.add(MaxPooling2D(pool_size=pool_size))\n",
        "        self.model.add(Dropout(0.2))\n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dense(128, activation='relu'))\n",
        "        self.model.add(Dense(50, activation='relu'))\n",
        "        self.model.add(Dense(15, activation='softmax'))\n",
        "\n",
        "        # Compile the model\n",
        "        print(\"Compiling Model...\")\n",
        "        self.model.compile(\n",
        "          optimizer='adam',\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'],\n",
        "        )\n",
        "\n",
        "    def load_model(self):\n",
        "        print('Loading Model...')\n",
        "        model_json = open('model/model.json', 'r')\n",
        "        loaded_model_json = model_json.read()\n",
        "        model_json.close()\n",
        "        loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "        print('Loading weights...')\n",
        "        loaded_model.load_weights(\"model/model_weights.h5\")\n",
        "\n",
        "        self.model = loaded_model\n",
        "\n",
        "    def train_model(self):\n",
        "        if not os.path.exists('model/train_data.csv'):\n",
        "            load_all_imgs()\n",
        "\n",
        "        csv_train_data = pd.read_csv('model/train_data.csv', index_col=False)\n",
        "\n",
        "        # The last column contain the results\n",
        "        y_train = csv_train_data[['784']]\n",
        "        csv_train_data.drop(csv_train_data.columns[[784]], axis=1, inplace=True)\n",
        "        csv_train_data.head()\n",
        "\n",
        "        y_train = np.array(y_train)\n",
        "\n",
        "        x_train = []\n",
        "        for i in range(len(csv_train_data)):\n",
        "            x_train.append(np.array(csv_train_data[i:i+1]).reshape(1, 28, 28))\n",
        "        x_train = np.array(x_train)\n",
        "        x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "\n",
        "        # Train the model.\n",
        "        print('Training model...')\n",
        "        self.model.fit(\n",
        "          x_train,\n",
        "          to_categorical(y_train, num_classes=15),\n",
        "          epochs=10,\n",
        "          batch_size=200,\n",
        "          shuffle=True,\n",
        "          verbose=1\n",
        "        )\n",
        "\n",
        "    def export_model(self):\n",
        "        model_json = self.model.to_json()\n",
        "        with open('model/model.json', 'w') as json_file:\n",
        "            json_file.write(model_json)\n",
        "        self.model.save_weights('model/model_weights.h5')\n",
        "\n",
        "    def predict(self, operationBytes):\n",
        "        Image.open(operationBytes).save('_aux_.png')\n",
        "        img = cv2.imread('_aux_.png',0)\n",
        "        os.remove('_aux_.png')\n",
        "        if img is not None:\n",
        "            img_data = extract_imgs(img)\n",
        "\n",
        "            operation = ''\n",
        "            for i in range(len(img_data)):\n",
        "                img_data[i] = np.array(img_data[i])\n",
        "                img_data[i] = img_data[i].reshape(-1, 28, 28, 1)\n",
        "\n",
        "                pred = self.model.predict(img_data[i])\n",
        "                result=np.argmax(pred,axis=1)\n",
        "                print(result[0])\n",
        "                if result[0] == 10:\n",
        "                    operation += '+'\n",
        "                elif result[0] == 11:\n",
        "                    operation += '-'\n",
        "                elif result[0] == 12:\n",
        "                    operation += 'x'\n",
        "                elif result[0] == 13:\n",
        "                    operation += 'a'\n",
        "                elif result[0] == 14:\n",
        "                    operation += 'b'\n",
        "                else:\n",
        "                    operation += str(result[0])\n",
        "            print(f\"Operation is {operation}\")\n",
        "            return operation\n",
        "CNN = ConvolutionalNeuralNetwork()\n"
      ],
      "metadata": {
        "id": "7P6c6E7zikDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Polynomial Solving Code"
      ],
      "metadata": {
        "id": "HQWqlZWo4yFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the necessary Modules\n",
        "from google.colab.patches import cv2_imshow\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "im = cv2.imread(\"eq.jpeg\",0) # Read the User Image\n",
        "im = cv2.resize(im,(600,200)) # Resize the User Image as per Model Requirement\n",
        "\n",
        "# Thresholding the User Image \n",
        "#===============================\n",
        "ret, thresh = cv2.threshold(im, 127, 255, 0)\n",
        "kernel = np.zeros((3,3),np.uint8)\n",
        "thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
        "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "thresh = thresh[10:,10:]\n",
        "cv2_imshow(thresh)\n",
        "#===============================\n",
        "\n",
        "\n",
        "# Conversion of the threshold image into base64 DataURL\n",
        "# This is done as our model requires base64 string to detect Equation/Polynomial\n",
        "#=================================================\n",
        "retval, buffer_img= cv2.imencode('.png', thresh)\n",
        "data = base64.b64encode(buffer_img)\n",
        "data = str(data)\n",
        "data = str(data)[2:len(data)-1]\n",
        "operation = BytesIO(base64.urlsafe_b64decode(data))\n",
        "#=================================================\n",
        "#Initializing the CNN model\n",
        "CNN = ConvolutionalNeuralNetwork()\n",
        "operation = CNN.predict(operation) # Feeding the base64 string to the the CNN Model\n",
        "print(eval(operation)) #print the result\n"
      ],
      "metadata": {
        "id": "mQUpKJ2C48M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Equation in One Variable"
      ],
      "metadata": {
        "id": "sfSO6jqS6u7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to solve Linear Equation in One Variable\n",
        "def solveEquation(equation,variable) :\n",
        "\n",
        "\tn = len(equation)\n",
        "\tsign = 1\n",
        "\tcoeff = 0\n",
        "\ttotal = 0\n",
        "\ti = 0\n",
        "\n",
        "\tfor j in range(0, n) :\n",
        "\t\n",
        "\t\tif (equation[j] == '+' or\n",
        "\t\t\tequation[j] == '-') :\n",
        "\t\t\n",
        "\t\t\tif (j > i) :\n",
        "\t\t\t\ttotal = (total + sign *\n",
        "\t\t\t\t\t\tfloat(equation[i: j]))\n",
        "\t\t\ti = j\n",
        "\n",
        "\t\telif (equation[j] == variable) :\n",
        "\t\t\n",
        "\t\t\tif ((i == j) or\n",
        "\t\t\t\tequation[j - 1] == '+') :\n",
        "\t\t\t\tcoeff += sign\n",
        "\t\t\telif (equation[j - 1] == '-') :\n",
        "\t\t\t\tcoeff = coeff - sign\n",
        "\t\t\telse :\n",
        "\t\t\t\tcoeff = (coeff + sign *\n",
        "\t\t\t\t\t\tfloat(equation[i: j]))\n",
        "\t\t\ti = j + 1\n",
        "\t\t\n",
        "\n",
        "\t\telif (equation[j] == '=') :\n",
        "\t\t\n",
        "\t\t\tif (j > i) :\n",
        "\t\t\t\ttotal = (total + sign *\n",
        "\t\t\t\t\t\tfloat(equation[i: j]))\n",
        "\t\t\tsign = -1\n",
        "\t\t\ti = j + 1\n",
        "\t\t\n",
        "\n",
        "\tif (i < n) :\n",
        "\t\ttotal = (total + sign *\n",
        "\t\t\t\tfloat(equation[i: len(equation)]))\n",
        "\n",
        "\n",
        "\tif (coeff == 0 and\n",
        "\t\ttotal == 0) :\n",
        "\t\treturn \"Infinite solutions\"\n",
        "\n",
        "\n",
        "\tif (coeff == 0 and total) :\n",
        "\t\treturn \"No solution\"\n",
        "\n",
        "\tans = -total / coeff\n",
        "\treturn float(ans)\n",
        "\n",
        "\n",
        "#Importing the necessary Modules\n",
        "from google.colab.patches import cv2_imshow\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "im = cv2.imread(\"eq.jpeg\",0) # Read the User Image\n",
        "im = cv2.resize(im,(600,200)) # Resize the User Image as per Model Requirement\n",
        "\n",
        "# Thresholding the User Image \n",
        "#===============================\n",
        "ret, thresh = cv2.threshold(im, 127, 255, 0)\n",
        "kernel = np.zeros((3,3),np.uint8)\n",
        "thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
        "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "thresh = thresh[10:,10:]\n",
        "cv2_imshow(thresh)\n",
        "#===============================\n",
        "\n",
        "\n",
        "# Conversion of the threshold image into base64 DataURL\n",
        "# This is done as our model requires base64 string to detect Equation/Polynomial\n",
        "#=================================================\n",
        "retval, buffer_img= cv2.imencode('.png', thresh)\n",
        "data = base64.b64encode(buffer_img)\n",
        "data = str(data)\n",
        "data = str(data)[2:len(data)-1]\n",
        "#=================================================\n",
        "#Initializing the CNN model\n",
        "operation = BytesIO(base64.urlsafe_b64decode(data))\n",
        "CNN = ConvolutionalNeuralNetwork()\n",
        "operation = CNN.predict(operation) # Feeding the base64 string to the the CNN Model\n",
        "if 'a' in operation:\n",
        "  print (\"a = {}\" .\n",
        "        format(solveEquation(operation,'a'))) # Feeding the String output to the solveEquation Function to evaluate the value of variable a\n",
        "if 'b' in operation:\n",
        "  print (\"b = {}\" .\n",
        "        format(solveEquation(operation,'b'))) # Feeding the String output to the solveEquation Function to evaluate the value of variable b\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B1TPZYfr6yzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Equation in Two Variable"
      ],
      "metadata": {
        "id": "r8NAcGTX7qH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the necessary Modules\n",
        "from sympy.parsing.sympy_parser import parse_expr\n",
        "from sympy import symbols, Eq, solve\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "ls = []\n",
        "filenames = [\"eq1.jpeg\",\"eq2.jpeg\"] #filenames for the linear equations\n",
        "#Run for loops for two times to get the two eqyations from the images specifed as filenames\n",
        "for i in range(0,2):\n",
        "  im = cv2.imread(filenames[i],0)# Read the User Image\n",
        "  im = cv2.resize(im,(600,200))# Resize the User Image as per Model Requirement\n",
        "\n",
        "  # Thresholding the User Image \n",
        "  #===============================\n",
        "  ret, thresh = cv2.threshold(im, 127, 255, 0)\n",
        "  kernel = np.zeros((3,3),np.uint8)\n",
        "  thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
        "  thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "  thresh = thresh[10:,10:]\n",
        "  cv2_imshow(thresh)\n",
        "  #===============================\n",
        "\n",
        "  # Conversion of the threshold image into base64 DataURL\n",
        "  # This is done as our model requires base64 string to detect Equation/Polynomial\n",
        "  #=================================================\n",
        "  retval, buffer_img= cv2.imencode('.png', thresh)\n",
        "  data = base64.b64encode(buffer_img)\n",
        "  data = str(data)\n",
        "  data = str(data)[2:len(data)-1]\n",
        "  #=================================================\n",
        "  #Initializing the CNN model\n",
        "  operation = BytesIO(base64.urlsafe_b64decode(data))\n",
        "  CNN = ConvolutionalNeuralNetwork()\n",
        "  operation = CNN.predict(operation)\n",
        "  ls.append(operation)\n",
        "  #=================================================\n",
        "\n",
        "#putting both equation in variables \n",
        "eq1 = ls[0]\n",
        "eq2 = ls[1]\n",
        "eq1 = comp(eq1)\n",
        "eq2 = comp(eq2)\n",
        "\n",
        "#Initializing the solving process using the sympy module \n",
        "\n",
        "x, y = symbols('a,b')\n",
        "eq1 = parse_expr(eq1)\n",
        "eq1 = Eq((eq1),0)\n",
        "eq2 = parse_expr(eq2)\n",
        "eq2 = Eq((eq2),0)\n",
        "\n",
        "print(eq1)\n",
        "\n",
        "print(eq2)\n",
        "\n",
        "\n",
        "# solving the equation\n",
        "print(\"Values of 2 unknown variable are as follows:\")\n",
        "  \n",
        "print(solve((eq1, eq2), (x, y)))\n"
      ],
      "metadata": {
        "id": "CIKotEvr7tMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7THfbLN-8Jos"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}